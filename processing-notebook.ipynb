{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f223471a",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Utilizaremos a biblioteca `boto3` para nos comunicarmos com a AWS.\n",
    "\n",
    "Utilizaremos as bibliotecas `pandas` e `pyspark` para lidarmos com nossos dados.\n",
    "\n",
    "Utilizaremos as bibliotecas `matplotlib` e `seaborn` para a análise final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2683da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e106465",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = '896309849144'\n",
    "LAYERS_PREFIX = f'layers'# f's3://{BUCKET}/layers'\n",
    "GOLD = f'{LAYERS_PREFIX}/gold'\n",
    "SILVER = f'{LAYERS_PREFIX}/silver'\n",
    "BRONZE = f'{LAYERS_PREFIX}/bronze'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "922c8c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "\n",
    "def upload_to_s3(\n",
    "        file_path : str,\n",
    "        bucket : str,\n",
    "        bucket_path : str):\n",
    "    '''\n",
    "    Uploads file_path to the given bucket, as bucket_path (include the name of the file in bucket_path)\n",
    "    \n",
    "    Parameters\n",
    "    -\n",
    "    file_path : str\n",
    "    bucket : str\n",
    "    bucket_path : str\n",
    "    '''\n",
    "    s3_client.upload_file(file_path, bucket, bucket_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cec076",
   "metadata": {},
   "source": [
    "# 0. Ingestion\n",
    "Faremos o upload dos dados brutos extraídos manualmente do IBGE, a um bucket AWS S3 via a biblioteca `boto3`.\n",
    "\n",
    "Conforme o pedido, utilizaremos os últimos 3 meses disponíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee5740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_BRONZE = './bronze'\n",
    "files = [\n",
    "    f'{LOCAL_BRONZE}/PNAD_COVID_092020.csv',\n",
    "    f'{LOCAL_BRONZE}/PNAD_COVID_102020.csv',\n",
    "    f'{LOCAL_BRONZE}/PNAD_COVID_112020.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1f84aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNAD_COVID_092020.csv\n",
      "PNAD_COVID_102020.csv\n",
      "PNAD_COVID_112020.csv\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    print(file.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7afc1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    upload_to_s3(\n",
    "        file,\n",
    "        BUCKET,\n",
    "        f'{BRONZE}/{file.split(\"/\")[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc197a3",
   "metadata": {},
   "source": [
    "# 1. Bronze\n",
    "O processo de re-estruturamento dos dados é feito na AWS via `AWS Glue`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db59f5fc",
   "metadata": {},
   "source": [
    "# 2. Silver\n",
    "Pegaremos esses dados re-estruturados *silver* e faremos nossas queries via `PySpark`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "761da2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_download = s3_client.list_objects_v2(\n",
    "    Bucket = BUCKET,\n",
    "    Prefix = SILVER\n",
    ")['Contents'][1:]\n",
    "\n",
    "count = 1\n",
    "\n",
    "LOCAL_SILVER = './local/silver'\n",
    "\n",
    "for file in to_download:\n",
    "    s3_client.download_file(BUCKET, file['Key'], f'{LOCAL_SILVER}/silver_{count}.parquet')\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929d93b1",
   "metadata": {},
   "source": [
    "## Checando integridade dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78f8149",
   "metadata": {},
   "source": [
    "Comparemos o tamanho da camade bronze original com a camada silver atual para nos certificarmos que o processo de merge ocorreu corretamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84233948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1149197"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_silver = pd.read_parquet('./local/')\n",
    "df_silver.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0cda0491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387298\n",
      "380461\n",
      "381438\n",
      "TOTAL = 1149197\n"
     ]
    }
   ],
   "source": [
    "row_count = 0\n",
    "for f in files[:]:\n",
    "    _ = pd.read_csv(f)\n",
    "    row_count += _.shape[0]\n",
    "\n",
    "    print(_.shape[0])\n",
    "print(f'TOTAL = {row_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29169435",
   "metadata": {},
   "source": [
    "## Selecionamento das perguntas\n",
    "Foi requesitado a utilização de no máximo 20 perguntas da pesquisa. Seguem as selecionadas abaixo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
